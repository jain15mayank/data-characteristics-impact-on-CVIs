{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pre-processing.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNgIc8UYOGMBCk3G1EmY4kY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"emnI5oZGEfd7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618164866887,"user_tz":-330,"elapsed":1407,"user":{"displayName":"Mayank Jain","photoUrl":"","userId":"09883289633884974344"}},"outputId":"b4f6268c-d7e2-447b-abe1-cec4c095a58d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hLAIK0lLTvjC"},"source":["# **Import Required Libraries**"]},{"cell_type":"code","metadata":{"id":"y5NmQl9wTqjw","executionInfo":{"status":"error","timestamp":1620431805042,"user_tz":-330,"elapsed":1513,"user":{"displayName":"Mayank Jain","photoUrl":"","userId":"09883289633884974344"}},"outputId":"925781d5-f6c6-4800-faca-2d24143d30b4","colab":{"base_uri":"https://localhost:8080/","height":333}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.axisartist.axislines import Subplot\n","from copy import copy, deepcopy\n","from pickle import dump, load\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/Load Demand Clustering Analysis/utils')\n","from utils import preProcessing_clustering"],"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-18b3b4003332>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab Notebooks/Load Demand Clustering Analysis/utils'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreProcessing_clustering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"markdown","metadata":{"id":"xdRZgXeJT1Am"},"source":["# **Import Data**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7nZsD_JjT11S","executionInfo":{"status":"ok","timestamp":1618165564715,"user_tz":-330,"elapsed":5770,"user":{"displayName":"Mayank Jain","photoUrl":"","userId":"09883289633884974344"}},"outputId":"0a81c5c0-1d76-4e24-ba10-a50e93055c27"},"source":["file_path = '/content/drive/My Drive/Colab Notebooks/Load Demand Clustering Analysis/data/15minute_data_austin.csv'\n","df = pd.read_csv(file_path)\n","print(df)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["        dataid       local_15min   grid  solar  solar2\n","0          661  01-01-2018 00:00    NaN    NaN     NaN\n","1          661  01-01-2018 00:15    NaN    NaN     NaN\n","2          661  01-01-2018 00:30    NaN    NaN     NaN\n","3          661  01-01-2018 00:45    NaN    NaN     NaN\n","4          661  01-01-2018 01:00  1.447 -0.002     NaN\n","...        ...               ...    ...    ...     ...\n","875888    9922  31-12-2018 22:45  1.238    NaN     NaN\n","875889    9922  31-12-2018 23:00  1.211    NaN     NaN\n","875890    9922  31-12-2018 23:15  1.045    NaN     NaN\n","875891    9922  31-12-2018 23:30  1.022    NaN     NaN\n","875892    9922  31-12-2018 23:45  1.205    NaN     NaN\n","\n","[875893 rows x 5 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"E01EEw_sULno"},"source":["# **Pre-Process Data**"]},{"cell_type":"markdown","metadata":{"id":"VwrIBA3-qUyF"},"source":["1.   Group data by Household ID\n","2.   Convert DateTime to Pandas DateTime for coherence - then sort by DateTime\n","3.   Add NANs if DateTime is not continuous for any household\n","4.   Make NAN to 0 to handle missing data\n","5.   Add eGauge readings of 'grid', 'solar', and 'solar2' to calculate net electricity consumption reading of the household\n","6.   If net electricity consumption value is -ve or 0, consider it as missing value by converting it to NAN\n","7.   Group data for each household by date\n","8.   Return final rawData of shape (nHouseholds, nDays, readingsPerDay)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ZjpHpVeUajL","executionInfo":{"status":"ok","timestamp":1618166336982,"user_tz":-330,"elapsed":36651,"user":{"displayName":"Mayank Jain","photoUrl":"","userId":"09883289633884974344"}},"outputId":"2e85acf7-8acd-4f16-8687-a8a218aadb6b"},"source":["nHouseholds = len(df['dataid'].unique().tolist())\n","print(nHouseholds)\n","rawData = []\n","for householdID, gp in df.groupby('dataid'):\n","    gp['local_15min'] = pd.to_datetime(gp['local_15min'], format=\"%d-%m-%Y %H:%M\")\n","    gp = gp.sort_values(by=\"local_15min\", ascending=True)\n","    #print(gp)\n","    #####\n","    ## Making Date column continuous by appending NANs (if required)\n","    #####\n","    '''\n","    print(len(gp.index))\n","    flag = 0\n","    while flag == 0:\n","        print('Inside While LOOP...')\n","        prev_value = 0\n","        for key, value in gp['local_15min'].iteritems():\n","            flag = 1\n","            if not prev_value == 0:\n","                time_diff = (value - prev_value).total_seconds() / 60.0\n","                if not (time_diff == 15 or time_diff == 75 or time_diff == -45 or time_diff == 0): # If DST is applicable - ignore it by allowing 75 and -45 minute time-difference\n","                    err_key = key\n","                    print('Found error at key =', err_key, 'and time_diff =', time_diff)\n","                    print('Proof of error:', err_key, value, prev_value, time_diff)\n","                    gp = pd.concat([gp.iloc[:err_key], pd.DataFrame({'local_15min': prev_value + pd.Timedelta(pd.offsets.Minute(15))}, index=[err_key]), gp.iloc[err_key:]]).reset_index(drop=True)\n","                    prev_value = prev_value + pd.Timedelta(pd.offsets.Minute(15))\n","                    err_key += 1\n","                    time_diff -= 15\n","                    while not time_diff == 15:\n","                        gp = pd.concat([gp.iloc[:err_key], pd.DataFrame({'local_15min': prev_value + pd.Timedelta(pd.offsets.Minute(15))}, index=[err_key]), gp.iloc[err_key:]]).reset_index(drop=True)\n","                        prev_value = prev_value + pd.Timedelta(pd.offsets.Minute(15))\n","                        err_key += 1\n","                        time_diff -= 15\n","                    flag = 0\n","                    break\n","            prev_value = value\n","    print(len(gp.index))\n","    '''\n","    #####\n","    ## Finsihed making Date column continuous by appending NANs (if required)\n","    #####\n","    gp['grid'] = gp['grid'].fillna(0)\n","    gp['solar'] = gp['solar'].fillna(0)\n","    gp['solar2'] = gp['solar2'].fillna(0)\n","    gp['elecConsume'] = gp.apply(lambda row: row.grid + row.solar + row.solar2, axis = 1)\n","    gp.loc[~(gp['elecConsume'] > 0), 'elecConsume']=np.nan\n","    #nDays = int(len(gp.index)/96) # Because we should get 96 readings per day - as we have 15 minute resolution\n","    nDays = len(gp['local_15min'].dt.date.unique().tolist())\n","    householdData = np.zeros((nDays, 96))\n","    dayCounter = 0\n","    for gpdate, gp1 in gp.groupby([gp['local_15min'].dt.date]):\n","        if (len(gp1.loc[:,'elecConsume'].values)==96):\n","            householdData[dayCounter,:] = gp1.loc[:,'elecConsume'].values\n","        else:\n","            print(gpdate, len(gp1.loc[:,'elecConsume'].values))\n","        dayCounter += 1\n","    rawData.append(householdData)\n","    #counter += gp['elecConsume'].isna().sum()\n","rawData = np.array(rawData)\n","print(rawData.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["25\n","2018-03-11 92\n","2018-04-09 92\n","2018-03-11 92\n","2018-03-11 92\n","2018-03-11 92\n","2018-03-11 92\n","2018-03-11 92\n","2018-03-11 92\n","2018-03-11 92\n","2018-03-11 92\n","2018-03-11 92\n","2018-03-11 92\n","2018-12-31 20\n","2018-03-11 92\n","2018-07-06 115\n","2018-07-07 162\n","2018-09-09 92\n","2018-03-11 92\n","2018-03-11 92\n","2018-03-11 92\n","2018-03-11 92\n","2018-03-11 92\n","2018-03-11 92\n","2018-03-11 92\n","2018-03-11 92\n","2018-03-11 92\n","2018-03-11 92\n","2018-01-01 88\n","2018-03-11 92\n","2018-03-11 92\n","2018-03-11 92\n","(25, 365, 96)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0ESssGNLrq9r"},"source":["1.   Extract median daily profiles for each household\n","2.   Normalize the median profiles to complete pre-processing\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H3nwBZfqrqB-","executionInfo":{"status":"ok","timestamp":1618166360019,"user_tz":-330,"elapsed":1730,"user":{"displayName":"Mayank Jain","photoUrl":"","userId":"09883289633884974344"}},"outputId":"5f9b2217-85af-4328-9d9c-0cb964ad707e"},"source":["processedData = preProcessing_clustering(rawData)\n","print(processedData.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(25, 96)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7CEXJpTiDv0L"},"source":["# **Save the Preprocessed Data**"]},{"cell_type":"code","metadata":{"id":"Y1E-nYGXDz-m"},"source":["dump(processedData, open('/content/drive/My Drive/Colab Notebooks/Load Demand Clustering Analysis/data/preProcessed_austin.pkl', 'wb'))\n","dump(rawData, open('/content/drive/My Drive/Colab Notebooks/Load Demand Clustering Analysis/data/rawData_austin.pkl', 'wb'))"],"execution_count":null,"outputs":[]}]}